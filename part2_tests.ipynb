{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b4b6c2-8a16-47e7-9d5f-65827b044a41",
   "metadata": {},
   "source": [
    "# Sujood and Guillem, 2 methods:\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/classification_threshold.html    -> LOOK at it for part 1 and part 2.\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/feature_selection.html\n",
    "    \n",
    "Separate into training and testing, as we will we doing some hyperparameter tuning.\n",
    "- For now we don't balance the original data, we may do it inside the model.\n",
    "- For now we are not standarizing anythin either, this can be changed and optimized.\n",
    "- Drop variables in full dataset we have that are full zeros or full ones we can never gain any information from those.\n",
    "\n",
    "Approach from class:\n",
    "\n",
    "1. BASELINE: Lasso for different alphas, this will give us different features, and data coded -1,1 so we can interpret as a linear probability model. We do not change the threshold so the threshold is 0. Advantage, no hypertuning, we can do this on the whole data. Alpha range from: {0.001, 0.040 tentative} and we get balanced accuracy on the test of 0.8 to below. \n",
    "  2. (1.1) We start tuning the threshold. This means hyper parameter tuning. We use 5 fold cross validation. The cross validation only occurs within the training data. What are we hyperparameter tuning? We just change the threshold, so we hyperparameter tune over optimal threshold and we take the average thresholds over the folds as the optimal threshold. Then we fit a lasso on the whole training data and we get a prediction based on optimal threshold for maximizing balanced accuracy. We iterate this procedure across many alphas. Gives like 0.87 for 20 features more or less.\n",
    "     \n",
    "Both approaches give us a plot of features vs balanced accuracy. We can consider them different models or we can consider them one. \n",
    "\n",
    "3. Forward feature selection:\n",
    "- We need to cut the initial number of variables somehow or this gets too computationally expensive.\n",
    "- Lasso is an aggressive way of cutting the variables, I think it will select p_lasso = N as a maximum, so it is very greedy. Use 0.0001 687 features.\n",
    "- Then this forward feature selection is another greedy approach. But nothing wrong with being greedy.\n",
    "Forward feature selection, does badly with local minima, maybe we have to tune that. Auto stops when two consecutive iterations can't improve. So in a sense prevents from overfitting but it also prevents from seeing beyond the slope.\n",
    "\n",
    "\n",
    "Cooking our own approaches: \n",
    "\n",
    "1. Lasso + SVM ():\n",
    "   For different alphas we train a Lasso on the whole data. We get a subset of X; based on which coefficients for the Lasso are not equal to 0. We then trained an out of the box SVC(radial kernel, we do not need any modifications, it just uses predict.). \n",
    "   WE DO SET: Class weights to balanced, this improves performance a bit, careful about doing this ad-hoc hyper parameter tuning. This was my hallucinations or not? WE should be careful.\n",
    "    7 features with 0.91 accuracy.\n",
    "    \n",
    "2. Lasso + SVM() + threshold tuning ():\n",
    "For different alphas we train a Lasso on the whole data. We get a subset of X; based on which coefficients for the Lasso are not equal to 0. We then trained an out of the box SVC(radial kernel, probability=True). This returns a probability for each class, we use the probability for the positive class to tune the threshold.\n",
    "    0.89 without class balance or anything.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "USE THIS THRESHOLD TUNING FOR PART 1, let's see if I can get a bit more.    \n",
    "\n",
    "Why is variance thresholding used? It doesn't make too much sense to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "19430193-bf66-4af0-8326-aa6b4664601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import json # Export dictionary of tuned parameters.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold # For hyperparameter tuning.\n",
    "\n",
    "\n",
    "# Evaluation metrics import\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Models import\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Visualisations import\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f1292-3500-4b17-b25a-e82fc1170dec",
   "metadata": {},
   "source": [
    "# Baseline approach, Lasso:\n",
    "\n",
    "The label is coded as -1 and 1 we can use Lasso as a classifier.\n",
    "\n",
    "We can try many lambdas and as a number of features we can get the ones with non zero beta coefficients.\n",
    "\n",
    "We fit on the training set and then we get\n",
    "\n",
    "- Regularize the data, use standard scaler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee788b2-9ff9-494d-8521-1d699d0e5522",
   "metadata": {},
   "source": [
    "# TIPS:\n",
    "FEATURE SELECTION:\n",
    "\n",
    "Feature selection methods, LASSO, and other lp penalties, LASSO IS GREAT because it sets to 0. Others I haven't tested.\n",
    "\n",
    "FORGET ABOUT AIC, BIC, subset selection, we can't fit those models it takes too long.\n",
    "\n",
    "Play around Lasso lambda to get more or less features.\n",
    "\n",
    "BE GREEDY! lASSO on subsets of the data. keep more variables as well. Low time approaches.\n",
    "\n",
    "https://stats.stackexchange.com/questions/27300/using-principal-component-analysis-pca-for-feature-selection (idk if this says something useful might be interesting to check.) And read the p>>n chapter of book for other methods. \n",
    "\n",
    "<hr>\n",
    "CLASSIFICATION:\n",
    "\n",
    "DICHOTOMY: CLASSIFICATION AND FEATURE SELECTION TO BE TREATED LIKE ORTHOGONAL ELEMENTS.\n",
    "\n",
    "Get variables from Lasso non zero coefficients and then fit a model, go big, svm, rf, whatever, don't try to classify using a Lasso. \n",
    "\n",
    "<hr>\n",
    "WORKFLOW:\n",
    "\n",
    "If we don't hyper parameter tune there is no reason we can't use CV for an estimate of the test error. We have few datapoints, every point is worth saving. ONLY IF WE DON'T HYPER PARAM TUNE WE CAN DO THIS, but baseline classification algorithms are already very good!.\n",
    "\n",
    "CLASSES VERY UNBALANCED, WE NEED TO TAKE THIS INTO ACCOUNT:\n",
    "REWEIGHTING things might be good for this. Some algorithms have options to reweight like rf or whatever.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef46c203-5100-4306-9666-949807fee80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for data, which is most important split.\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d136e9a-e49e-437f-8a58-72349219cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bba3e67-9116-404c-b92c-d1ea18f13085",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Datasets/data2.csv.gz\" \n",
    "\n",
    "# Load the dataset\n",
    "data = load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9495b2c-c1b5-485f-99e6-4be2b55c9798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>99990</th>\n",
       "      <th>99991</th>\n",
       "      <th>99992</th>\n",
       "      <th>99993</th>\n",
       "      <th>99994</th>\n",
       "      <th>99995</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "      <th>99998</th>\n",
       "      <th>99999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 100001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  0  1  2  3  4  5  6  7  8  ...  99990  99991  99992  99993  99994  \\\n",
       "0       -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "1       -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "2       -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "3       -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "4       -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "..     ... .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...    ...    ...   \n",
       "795     -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "796     -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "797     -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "798     -1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "799      1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0      0   \n",
       "\n",
       "     99995  99996  99997  99998  99999  \n",
       "0        0      0      1      0      0  \n",
       "1        0      0      0      0      0  \n",
       "2        0      0      0      0      0  \n",
       "3        0      0      0      0      0  \n",
       "4        0      0      0      0      1  \n",
       "..     ...    ...    ...    ...    ...  \n",
       "795      0      0      0      0      1  \n",
       "796      0      0      0      0      0  \n",
       "797      0      0      0      0      0  \n",
       "798      0      0      0      0      0  \n",
       "799      0      0      0      0      0  \n",
       "\n",
       "[800 rows x 100001 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "80aa338a-5081-4fb2-89ab-7bd603861ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(threshold, y):\n",
    "    # Ensure the input is a NumPy array\n",
    "    y = np.array(y, copy=True)\n",
    "    \n",
    "    # Apply the thresholding logic\n",
    "    y_binarized = np.where(y >= threshold, 1, 0)\n",
    "    \n",
    "    return y_binarized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8fd17e13-4e71-4c98-a978-070a96f16298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "thresholds = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9]\n",
    "fold_optimal = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "    x_train_cv = X_train.iloc[train_index, :]\n",
    "    x_test_cv = X_train.iloc[test_index,:]\n",
    "    y_train_cv = y_train.iloc[train_index]\n",
    "    y_test_cv = y_train.iloc[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    lasso = Lasso(alpha= 0.1)\n",
    "    lasso.fit(x_train_cv, y_train_cv)\n",
    "    y_pred = lasso.predict(x_test_cv)\n",
    "\n",
    "    fold_scores = []\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        y_label = thresholding(threshold, y_pred)\n",
    "        fold_scores.append(balanced_accuracy_score(y_test_cv, y_label))\n",
    "\n",
    "    fold_optimal.append(thresholds[np.argmax(fold_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef1f6d-b5a8-4539-b4f9-bd4d284de501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb23ba5-e830-41b6-b89d-2f77a1027fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647bdba-76af-4e3b-98ad-edaa5c43b3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee19ad1-f1c1-4873-b7a3-7cfc77a2e968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366a0cf7-2ae3-43d5-9184-905da2489b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1    722\n",
       " 1     78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()\n",
    "# DATA IS VERY UNBALANCED, SOME ESTIMATORS HAVE OPTIONS TO REWEIGHT THE DATA!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bb213d7-076e-41ec-8cfb-34478688fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "balanced_accuracy = balanced_accuracy_score(y_TEST_G, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd9f6b-093d-40d2-9830-345ecb28d1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "731093d5-ac38-408c-8c48-c384097587a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7743055555555556)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets worse the bigger the test, meaning we train with less data. Try pure CV and reweighting methods.\n",
    "balanced_accuracy\n",
    "# 0.9 balanced accuracy as baseline if I am not mistaken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2cca8ff8-55ec-4e95-b246-2952759d6d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   -1\n",
       "2   -1\n",
       "3   -1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].iloc[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d6c60ea-598d-45aa-898c-93d72847547e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.531e-03, tolerance: 5.599e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Lasso alpha0.0001, number of parameters for the random forest 638, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 14.35176134109497\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0006, number of parameters for the random forest 491, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 5.116127014160156\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0011, number of parameters for the random forest 374, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 2.6300270557403564\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0016, number of parameters for the random forest 294, \n",
      "    balanced accuracy 0.8090277777777778, lasso fit time 1.9154973030090332\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0021, number of parameters for the random forest 226, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 1.4705348014831543\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0026, number of parameters for the random forest 169, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 1.3455009460449219\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0031, number of parameters for the random forest 135, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 1.2205631732940674\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0036, number of parameters for the random forest 100, \n",
      "    balanced accuracy 0.7777777777777778, lasso fit time 1.0581870079040527\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0041, number of parameters for the random forest 77, \n",
      "    balanced accuracy 0.7430555555555556, lasso fit time 0.960456371307373\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0046, number of parameters for the random forest 60, \n",
      "    balanced accuracy 0.7430555555555556, lasso fit time 0.9604020118713379\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0051, number of parameters for the random forest 41, \n",
      "    balanced accuracy 0.7777777777777778, lasso fit time 0.9267909526824951\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0056, number of parameters for the random forest 33, \n",
      "    balanced accuracy 0.8020833333333333, lasso fit time 0.8777711391448975\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0061, number of parameters for the random forest 23, \n",
      "    balanced accuracy 0.7708333333333333, lasso fit time 0.8487989902496338\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0066, number of parameters for the random forest 19, \n",
      "    balanced accuracy 0.8263888888888888, lasso fit time 0.8198208808898926\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0071, number of parameters for the random forest 15, \n",
      "    balanced accuracy 0.8854166666666667, lasso fit time 0.7977809906005859\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0076, number of parameters for the random forest 10, \n",
      "    balanced accuracy 0.8541666666666667, lasso fit time 0.7113890647888184\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0081, number of parameters for the random forest 9, \n",
      "    balanced accuracy 0.7604166666666667, lasso fit time 0.7032110691070557\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0086, number of parameters for the random forest 7, \n",
      "    balanced accuracy 0.8576388888888888, lasso fit time 0.7092452049255371\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0091, number of parameters for the random forest 6, \n",
      "    balanced accuracy 0.8541666666666667, lasso fit time 0.7082920074462891\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0096, number of parameters for the random forest 6, \n",
      "    balanced accuracy 0.8541666666666667, lasso fit time 0.7449681758880615\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0101, number of parameters for the random forest 6, \n",
      "    balanced accuracy 0.8576388888888888, lasso fit time 0.6825041770935059\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0106, number of parameters for the random forest 6, \n",
      "    balanced accuracy 0.8541666666666667, lasso fit time 0.7106029987335205\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0111, number of parameters for the random forest 6, \n",
      "    balanced accuracy 0.8576388888888888, lasso fit time 0.6814308166503906\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0116, number of parameters for the random forest 5, \n",
      "    balanced accuracy 0.8576388888888888, lasso fit time 0.6679649353027344\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0121, number of parameters for the random forest 5, \n",
      "    balanced accuracy 0.8576388888888888, lasso fit time 0.7124407291412354\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0126, number of parameters for the random forest 4, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6499557495117188\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0131, number of parameters for the random forest 4, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.651310920715332\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0136, number of parameters for the random forest 4, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6565492153167725\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0141, number of parameters for the random forest 4, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.667546272277832\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0146, number of parameters for the random forest 4, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6656708717346191\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0151, number of parameters for the random forest 4, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.663020133972168\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0156, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6638422012329102\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0161, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6378319263458252\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0166, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6204507350921631\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0171, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6171708106994629\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0176, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6233730316162109\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0181, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.61897873878479\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0186, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6082799434661865\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0191, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6099193096160889\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0196, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6131153106689453\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0201, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.603186845779419\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0206, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6075429916381836\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0211, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6040079593658447\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0216, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6104879379272461\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0221, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.7743055555555556, lasso fit time 0.6021199226379395\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0226, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6175827980041504\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0231, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5883660316467285\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0236, number of parameters for the random forest 3, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.6223249435424805\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0241, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5506408214569092\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0246, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5493350028991699\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0251, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5555808544158936\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0256, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.55129075050354\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0261, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5373671054840088\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0266, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5383810997009277\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0271, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5352540016174316\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0276, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5386407375335693\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0281, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5215127468109131\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0286, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5272800922393799\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0291, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5079798698425293\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0296, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5127918720245361\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0301, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.5098598003387451\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0306, number of parameters for the random forest 2, \n",
      "    balanced accuracy 0.8333333333333333, lasso fit time 0.4733619689941406\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0311, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.33102893829345703\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0316, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.33298420906066895\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0321, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.340224027633667\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0326, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.32845115661621094\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0331, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.35213398933410645\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0336, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3271009922027588\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0341, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3324289321899414\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0346, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3284261226654053\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0351, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3273181915283203\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0356, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.32997798919677734\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0361, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3278641700744629\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0366, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3930220603942871\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0371, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.35103893280029297\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0376, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.47560811042785645\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0381, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.49401402473449707\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0386, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.39472508430480957\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0391, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.34069395065307617\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0396, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3340339660644531\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0401, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.38985323905944824\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0406, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.39424800872802734\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0411, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3362581729888916\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0416, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.37623023986816406\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0421, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3345189094543457\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0426, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.410175085067749\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0431, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.33680105209350586\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0436, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3292500972747803\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0441, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.33254384994506836\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0446, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3313620090484619\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0451, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3495790958404541\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0456, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.34784412384033203\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0461, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3267509937286377\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0466, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.328305721282959\n",
      "    \n",
      "\n",
      "    Lasso alpha0.0471, number of parameters for the random forest 1, \n",
      "    balanced accuracy 0.8055555555555556, lasso fit time 0.3462231159210205\n",
      "    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(640, 0)) while a minimum of 1 is required by RandomForestClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_TRAIN_G\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlasso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_TRAIN_G\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_TEST_G[:,lasso\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m balanced_accuracy \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_TEST_G, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/m_learn/lib/python3.13/site-packages/sklearn/utils/validation.py:1096\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[0;32m-> 1096\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1097\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[1;32m   1100\u001b[0m         )\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_writeable:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;66;03m# By default, array.copy() creates a C-ordered copy. We set order=K to\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;66;03m# preserve the order of the array.\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m     copy_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array) \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(640, 0)) while a minimum of 1 is required by RandomForestClassifier."
     ]
    }
   ],
   "source": [
    "for i in range(1,1000,5):\n",
    "    tic = time.time()\n",
    "    lasso = Lasso(alpha=i/10000)\n",
    "    \n",
    "    lasso.fit(X_TRAIN_G,y_TRAIN_G)\n",
    "    toc = time.time()\n",
    "    rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "    rf.fit(X_TRAIN_G[:,lasso.coef_!=0],y_TRAIN_G)\n",
    "    y_pred = rf.predict(X_TEST_G[:,lasso.coef_!=0])\n",
    "    balanced_accuracy = balanced_accuracy_score(y_TEST_G, y_pred)\n",
    "\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Lasso alpha{i/10000}, number of parameters for the random forest {X_TRAIN_G[:,lasso.coef_!=0].shape[1]}, \n",
    "    balanced accuracy {balanced_accuracy}, lasso fit time {toc-tic}\n",
    "    \"\"\"\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
