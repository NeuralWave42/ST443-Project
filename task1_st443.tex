\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx} % Required for inserting images
\usepackage{algpseudocodex}
% \usepackage[preprint]{neurips_2024}
\usepackage[preprint]{neurips_2024}
\begin{document}

\section{Preliminary data analysis}

TO DO LIST:
\begin{itemize}
    \item Basic summary stats? Size and shape of the dataset
    \item Class balance
    \item Sparsity or something like that?
    \item For plots, we could try biplot, check if I understood Milan's explanation?
    \item The nicest we can do is reduce the dimensionality to 2 factors and plot by hue class. 
    Or just pick 2 first factors from pca.
    \item More importantly we need some kind of scree plot. To justify working on the PCA. Implementation of the scree plot. We can 
    jsut add the components explained variance with cumsum and it works.
    \item Correct way to use t-sne if we have space is to plot different perplexities.
\end{itemize}


\section{Training baseline models and hypertuning}

\begin{itemize}
    \item Most tuning is done, VSM give very good results.
    \item 
    \item RESULTS FROM GRIDSEARCH ARE NOT GOING TO BE REPLICABLE, RESULTS FROM FINAL ESTIMATOR BASED ON IT SHOULD BE.
\end{itemize}


\section{Our 3 models}

\begin{itemize}
    \item AdaBoost, just because we have seen it in class and it could be interesting.
    \item I wanted some classically strong classifier like random forest or GBDT?
    \item Play around with the PCA optimality. Or some other modern dimensionality reduction tool like t-SNE or UMAP. 
\end{itemize}

\section{}


\end{document}