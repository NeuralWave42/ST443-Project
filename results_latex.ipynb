{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176c4cb6-52e6-47df-b6e9-78002ef6adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff325da-d8b5-430a-a07b-9f66b95880cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_format_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b45b5cb5-3dbf-4aa5-b00d-5a967ce07746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PCA\"] = df[\"Model\"].apply(lambda row: True if row[len(row)-4:len(row)]==\"_pca\" else False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2defe7ef-ac9f-4503-bbe2-34ef101968fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bff16daa-e846-4451-85d4-3297ccabb0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Model\"] = df[\"Model\"].apply(lambda row: row[0:len(row)-4] if row[len(row)-4:len(row)]==\"_pca\" else row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ac8a43c-f1b9-452f-9447-debe3a0ee022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Model\"] = df[\"Model\"].str.upper() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c5a00d2-6daa-4191-975b-8f756eeab641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "[\"Accuracy\",\"Balanced Accuracy\", \"AUC\", \"F1 Score\"]\n",
    "] = df[\n",
    "[\"Accuracy\",\"Balanced Accuracy\", \"AUC\", \"F1 Score\"]\n",
    "].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3eb3e480-d4c0-4fce-8db5-4e9bfe7d0219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrl}\n",
      "\\toprule\n",
      "Model & Accuracy & Balanced Accuracy & AUC & F1 Score & Confusion Matrix \\\\\n",
      "\\midrule\n",
      "LDA & 0.965 & 0.956 & 0.993 & 0.951 & [[687, 6], [32, 370]] \\\\\n",
      "LOGIT & 0.958 & 0.954 & 0.993 & 0.942 & [[672, 21], [25, 377]] \\\\\n",
      "QDA & 0.367 & 0.500 & 0.500 & 0.537 & [[0, 693], [0, 402]] \\\\\n",
      "KNN & 0.788 & 0.777 & 0.874 & 0.718 & [[567, 126], [106, 296]] \\\\\n",
      "SVM & 0.956 & 0.953 & 0.993 & 0.940 & [[669, 24], [24, 378]] \\\\\n",
      "RF & 0.943 & 0.924 & 0.993 & 0.917 & [[690, 3], [59, 343]] \\\\\n",
      "GBDT & 0.963 & 0.955 & 0.994 & 0.949 & [[684, 9], [31, 371]] \\\\\n",
      "LDA & 0.950 & 0.936 & 0.994 & 0.928 & [[685, 8], [47, 355]] \\\\\n",
      "LOGIT & 0.966 & 0.965 & 0.994 & 0.954 & [[672, 21], [16, 386]] \\\\\n",
      "QDA & 0.960 & 0.958 & 0.993 & 0.946 & [[669, 24], [20, 382]] \\\\\n",
      "KNN & 0.928 & 0.911 & 0.956 & 0.896 & [[675, 18], [61, 341]] \\\\\n",
      "SVM & 0.967 & 0.966 & 0.994 & 0.956 & [[672, 21], [15, 387]] \\\\\n",
      "RF & 0.957 & 0.947 & 0.989 & 0.940 & [[683, 10], [37, 365]] \\\\\n",
      "GBDT & 0.947 & 0.938 & 0.990 & 0.926 & [[673, 20], [38, 364]] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"Model\",\"Accuracy\",\"Balanced Accuracy\", \"AUC\", \"F1 Score\",\"Confusion Matrix\"]\n",
    "].to_latex(float_format=\"%.3f\", index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
